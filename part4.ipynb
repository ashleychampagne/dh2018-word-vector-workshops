{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Reading: Advanced Topics in Word Vectors\n",
    "## Part IV. Role of Bias in Word Embeddings (50 mins)\n",
    "\n",
    "This is a 4-part series of Jupyter notebooks on the topic of word embeddings originally created for a workshop during the Digital Humanities 2018 Conference in Mexico City. Each part is comprised of a mix of theoretical explanations and fill-in-the-blanks activities of increasing difficulty.\n",
    "\n",
    "Instructors:\n",
    "- Eun Seo Jo, <a href=\"mailto:eunseo@stanford.edu\">*eunseo@stanford.edu*</a>, Stanford University\n",
    "- Javier de la Rosa, <a href=\"mailto:versae@stanford.edu\">*versae@stanford.edu*</a>, Stanford University\n",
    "- Scott Bailey, <a href=\"mailto:scottbailey@stanford.edu\">*scottbailey@stanford.edu*</a>, Stanford University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this unit, we will explore an application and caveat of using word embeddings -- cultural bias. Presenting methods and results from recent articles, we will show how word embeddings can carry the historical bias of the training corpora and lead an activity that shows these human-biases on vectors. We'll also address how such bias can be mitigated.\n",
    "\n",
    "- 0:00 - 0:10 Algorithmic bias vs human bias \n",
    "- 0:10 - 0:40 [Activity 4] Identifying bias in corpora (occupations, gender, ...) [GloVe]\n",
    "- 0:40 - 0:50 Towards unbiased embeddings; Examine “debiased” embeddings\n",
    "- 0:50 - 0:60 Concluding remarks and debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy nltk scikit-learn matplotlib gensim seaborn plotly;\n",
    "!python -m nltk.downloader all;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "# import plotly.plotly as py\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 1em; margin: 1em 0 1em 0; border: 1px solid #86989B; background-color: #f7f7f7; padding: 0;\">\n",
    "<p style=\"margin: 0; padding: 0.1em 0 0.1em 0.5em; color: white; border-bottom: 1px solid #86989B; font-weight: bold; background-color: #AFC1C4;\">\n",
    "Activity\n",
    "</p>\n",
    "<p style=\"margin: 0.5em 1em 0.5em 1em; padding: 0;\">\n",
    "Your turn: Generate a vector including integers from 4 and 8 of size 10\n",
    "<br>\n",
    "<em>\n",
    "<strong>Hint</strong>: Use the numpy functions\n",
    "</em>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will work through examples from a paper that came out in 2016 on debiasing gender vectors. (https://arxiv.org/pdf/1607.06520.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import debiaswe as dwe\n",
    "import debiaswe.we as we\n",
    "from debiaswe.we import WordEmbedding\n",
    "from debiaswe.data import load_professions\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first load our embedddings with the code the authors provide\n",
    "E = WordEmbedding('./embeddings/w2v_gnews_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The authors also give us a hand-picked set of definitional gender pairs, pairs of gender words we want to equalize, and words that are gender-specific  \n",
    "\n",
    "with open('./data/definitional_pairs.json', \"r\") as f:\n",
    "    defs = json.load(f)\n",
    "print(\"definitional\", defs)\n",
    "\n",
    "with open('./data/equalize_pairs.json', \"r\") as f:\n",
    "    equalize_pairs = json.load(f)\n",
    "\n",
    "with open('./data/gender_specific_seed.json', \"r\") as f:\n",
    "    gender_specific_words = json.load(f)\n",
    "print(\"gender specific\", len(gender_specific_words), gender_specific_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalize_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_specific_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also get a list of professions\n",
    "professions = load_professions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem we're dealing with here? Where is the 'bias'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We identify a gender subspace or direction by subtracting the 'he' vector from the 'she' vector\n",
    "gender_vector = E.diff('she','he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cosine similarity, see how gender specific words (such as 'boyfriend' or 'actress') relate to the gender vector\n",
    "for w in gender_specific_words:\n",
    "    if w in E.index:\n",
    "        print (w, cosine_similarity(E.v(w).reshape(1,-1), gender_vector.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity: Make your own list of words that you think will be demonstrate or embed bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at how these 'biases' are reflected in our hand-picked set of profession-related words.\n",
    "for w in [p[0] for p in professions]:\n",
    "    if w in E.index:\n",
    "        print (w, cosine_similarity(E.v(w).reshape(1,-1), gender_vector.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While as humanists and social scientists we might find such discrepancies, or rather consistent biases, interesting data, computer scientists found this embedded bias deeply problematic (and perhaps horrifying). So, they have tried to correct these discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.v('physicist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physicist = E.v('physicist')/la.norm(E.v('physicist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = np.dot(physicist,gender_vector.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_comp = np.multiply(gender_vector, factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased = physicist - bias_comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(debiased.reshape(1,-1), gender_vector.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(physicist.reshape(1,-1), gender_vector.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_debiasing = sorted([(w,cosine_similarity(E.v(w).reshape(1,-1),gender_vector.reshape(1,-1))) for w in profession_words], key=lambda x:x[1][[0]])\n",
    "before_debiasing[:15], before_debiasing[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from debiaswe.debias import debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debias(E, gender_specific_words, defs, equalize_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_debiasing = sorted([(w,cosine_similarity(E.v(w).reshape(1,-1),gender_vector.reshape(1,-1))) for w in profession_words], key=lambda x:x[1][[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_debiasing[:15], after_debiasing[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gender_debiased = E.best_analogies_dist_thresh(v_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sorted([(E.v(w).dot(v_gender), w) for w in profession_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./glove/glove.6B.50d.txt','rb') as lines:\n",
    "    w2v = {line.split()[0].decode('utf-8'): np.array(list(map(float, line.split()[1:]))).reshape(1,50)\n",
    "           for line in lines}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$S_{(a,b)}(x,y) = \n",
    "  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      cos(\\vec{a} - \\vec{b},\\vec{x} - \\vec{y})& if \\left\\Vert \\vec{x} - \\vec{y} \\right\\Vert \\leq \\delta \\\\\n",
    "      0 & otherwise \\\\\n",
    "\\end{array} \n",
    "\\right. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gender = E.best_analogies_dist_thresh(v_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_gender[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sorted([(E.v(w).dot(v_gender), w) for w in profession_words])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
